<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://example.com</id>
    <title>自是白衣卿相的博客</title>
    <subtitle></subtitle>
    <icon>http://example.com/images/favicon.ico</icon>
    <link href="http://example.com" />
    <author>
      <name>Miralce</name>
    </author>
    <updated>2024-02-23T16:00:00.000Z</updated>
    <category term="博客 笔记" />
    <entry>
        <id>http://example.com/neural_network/transformer/</id>
        <title>Transformer 备忘录</title>
        <link rel="alternate" href="http://example.com/neural_network/transformer/"/>
        <content type="html">&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;为什么选择 Transformer&lt;br&gt;
NLP 任务需要编码器抽取上下文的特征&lt;br&gt;
上下文的语义很重要，每个词的语义和上下文强相关&lt;br&gt;
方向&lt;br&gt;
 RNN 只能对句子进行单向的编码&lt;br&gt;
 CNN 只能对短句子进行编码&lt;br&gt;
 Transformer 可以双向编码，也抽取长距离的特征&lt;br&gt;
顺序（词的位置变换了会产生不同的意思）&lt;br&gt;
速度&lt;br&gt;
 RNN 无法并行处理序列，其他都行&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多头自注意力模块&lt;br&gt;
首先对输入进行 projection，得到 QKV 三个矩阵&lt;br&gt;
（tf 对输入进行了降维 (B, L, D) -&amp;gt; (B&lt;em&gt;L, D)）&lt;br&gt;
初始化三个 dense 层 (B&lt;/em&gt;L, D) -&amp;gt; (B&lt;em&gt;L, N&lt;/em&gt;H) N 为 attention 模块的数量，H 为长度&lt;br&gt;
为什么要在这个进行投影呢？&lt;br&gt;
若不投影，在之后的注意力模块中，相同的 Q 和 V 会进行点积，使得 attention 矩阵对角线的分数特别高（自己和自己的分数？），每个词的注意力都在自己身上，无法获得上下文的关系。所以需要将 QKV 投影到不同的空间中，增加多样性。&lt;/p&gt;
&lt;p&gt;之后进行 reshape, (B&lt;em&gt;L, N&lt;/em&gt;H) -&amp;gt; (B, N, L, H)&lt;br&gt;
 为什么要用多注意力头呢？&lt;br&gt;
希望不同的注意力头学到不同的特征，和 CNN 里的 multi-channel 类似&lt;/p&gt;
&lt;p&gt;多不同的注意力头进行点积、转置&lt;br&gt;
为什么要用乘法呢？（为什么不用加性 attention 呢？）&lt;br&gt;
在 GPU 的场景下，矩阵乘法的效率更高，随着 D 的增大，加性 attention 的效果会更好&lt;br&gt;
为什么要除以√D 呢？&lt;br&gt;
两个的矩阵相乘之后方差会变大，使得有些词注意力很大有些很小，经过 softmax 之后再求导会导致梯度很小，不利于优化，除了之后可以平滑一下。e.g. N (0, √d)*N (0, √d) = N (0, d) -&amp;gt; / √d -&amp;gt; N (0, 1)。&lt;/p&gt;
&lt;p&gt;乘 mask 矩阵（正常 token 的值为 0，要丢弃的 token 值为 1w）使得正常 token 的值维持原状，被丢弃的 token 值很小。使得进过 softmax 之后，不想要被注意的值无限趋于 0&lt;/p&gt;
&lt;p&gt;进行 softmax 归一化得到注意力分数&lt;/p&gt;
&lt;p&gt;用 V 矩阵和注意力分数进行加权，再把不同头的分数合并起来&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;残差连接 &amp;amp; Normalisation&lt;br&gt;
 相加操作与 ResNet 相似，相当于在求导时加了一个恒等项，减少梯度消失的问题&lt;/p&gt;
&lt;p&gt;Layer_Norm&lt;br&gt;
 提升神经网络的泛化性&lt;br&gt;
（数据的分布对模型可能会有很大的影响）&lt;br&gt;
所以需要将隐藏层的输出都归一化成均值为 0 方差为 1 的分布&lt;br&gt;
更好的利用模型在训练集中收获的知识&lt;br&gt;
 norm 放在激活函数之前，避免数据落入饱和区，减少梯度消失的问题&lt;br&gt;
（实际操作时会初始化一个新的均值和方差，调整分布，增加多样性）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; NLP的序列是变长的，Batch_Norm在对不同样本的同一个位置去做归一化时，无法获得真实分布的统计值。
 Layer_Norm会对同一个样本每一个位置的不同特征做归一化


 

 Normalisation可以放在不同的地方
     Post-LayerNorm先做残差再归一化
         保持主干网络的方差比较稳定，使模型泛化能力更强。
         但把恒等的路径放在norm里，会导致模型更难收敛。
     Pre-LayerNorm先归一化再做残差
         更容易收敛，但只是增加了网络的宽度而不是深度，效果没有前者好。
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Positionwise FFN (Feed Forward Network)&lt;br&gt;
 提供了非线性变换，提升拟合能力 (1*1 卷积核的全连接层)。&lt;br&gt;
激活层从 ReLU 变成了 GeLU，引入了正则的思想，越小的值越可能被丢弃掉，相当于 ReLU 和 dropout 的结合。&lt;br&gt;
tanh 和 sigmoid 的双边区域会饱和，导致导数趋于 0，有梯度消失的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
        <category term="神经网络" scheme="http://example.com/categories/neural-network/" />
        <category term="自然语言处理" scheme="http://example.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" />
        <updated>2024-02-23T16:00:00.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/projects/alzheimer/</id>
        <title>Alzheimer’s Disease Detection using Disfluencies Implemented Fine-Tuning BERT Model Ensemble</title>
        <link rel="alternate" href="http://example.com/projects/alzheimer/"/>
        <content type="html">&lt;ol&gt;
&lt;li&gt;背景介绍&lt;br&gt;
使用原始的、未注释的、未转录的语音进行目标认知状态预测，并解决认知随时间变化的预测。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;address 挑战：阿尔茨海默氏痴呆症识别仅通过自发语言&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从一个简短的演讲中检测阿尔茨海默氏痴呆症&lt;/li&gt;
&lt;li&gt;认知测试分数的推断，MMSE 分数。&lt;/li&gt;
&lt;li&gt;预测认知能力下降&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;任务:&lt;br&gt;
 从一个简短的演讲中检测阿尔茨海默氏痴呆症&lt;/p&gt;
&lt;p&gt;可能的一般方法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直接使用语音信号 (声学特征)&lt;/li&gt;
&lt;li&gt;语音自动转换为文本 (ASR)，并从脚本中提取语言特征&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更好的解决方案:&lt;br&gt;
 结合声学和语言特征，利用预训练 BERT 模型。&lt;/p&gt;
</content>
        <category term="科研项目" scheme="http://example.com/categories/projects/" />
        <category term="自然语言处理" scheme="http://example.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" />
        <updated>2024-02-23T16:00:00.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/hello-world/</id>
        <title>Hello World</title>
        <link rel="alternate" href="http://example.com/hello-world/"/>
        <content type="html">&lt;p&gt;Welcome to &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvLw==&#34;&gt;Hexo&lt;/span&gt;! This is your very first post. Check &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv&#34;&gt;documentation&lt;/span&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=&#34;&gt;troubleshooting&lt;/span&gt; or you can ask me on &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==&#34;&gt;GitHub&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#quick-start&#34;&gt;#&lt;/a&gt; Quick Start&lt;/h2&gt;
&lt;h3 id=&#34;create-a-new-post&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#create-a-new-post&#34;&gt;#&lt;/a&gt; Create a new post&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo new &lt;span class=&#34;string&#34;&gt;&amp;quot;My New Post&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s&#34;&gt;Writing&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;run-server&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#run-server&#34;&gt;#&lt;/a&gt; Run server&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo server&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=&#34;&gt;Server&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;generate-static-files&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#generate-static-files&#34;&gt;#&lt;/a&gt; Generate static files&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo generate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s&#34;&gt;Generating&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;deploy-to-remote-sites&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#deploy-to-remote-sites&#34;&gt;#&lt;/a&gt; Deploy to remote sites&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo deploy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvb25lLWNvbW1hbmQtZGVwbG95bWVudC5odG1s&#34;&gt;Deployment&lt;/span&gt;&lt;/p&gt;
</content>
        <updated>2024-02-18T10:04:35.837Z</updated>
    </entry>
    <entry>
        <id>http://example.com/travel/japan/food/</id>
        <title>日本行美食总结</title>
        <link rel="alternate" href="http://example.com/travel/japan/food/"/>
        <content type="html">&lt;h1 id=&#34;神户&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#神户&#34;&gt;#&lt;/a&gt; 神户&lt;/h1&gt;
&lt;h2 id=&#34;くつろぎ家kutsurogiya&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#くつろぎ家kutsurogiya&#34;&gt;#&lt;/a&gt; くつろぎ家（Kutsurogiya）&lt;/h2&gt;
&lt;p&gt;网红的平价米其林（2016 年米其林推荐），招牌釜饭确实好吃 &lt;strong&gt;『くつろぎ釜飯』&lt;/strong&gt;，内涵鲷鱼鲑鱼章鱼及蔬菜，味道很有层次。网红的蒸和牛 **『湯けむり蒸し』** 是牛肉与蔬菜在小蒸笼里现场蒸制，本身没有调味，即便有酱料蘸碟还是觉得乏善可陈。当地人基本都只点釜饭，点和牛的都是游客。有小碟点心小菜，杏仁豆腐什么的。冬季限定有牡蛎釜饭。&lt;/p&gt;
&lt;p&gt;有馬温泉駅 徒歩 5 分 日式榻榻米风格餐厅&lt;/p&gt;
&lt;p&gt;不支持预定，仅能 walk-in 排队，cash only，人均 200+RMB&lt;/p&gt;
&lt;h2 id=&#34;神戸豚骨ラーメン-賀正軒gashoken&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#神戸豚骨ラーメン-賀正軒gashoken&#34;&gt;#&lt;/a&gt; 神戸豚骨ラーメン 賀正軒（Gashoken）&lt;/h2&gt;
&lt;p&gt;除了传统的豚骨拉面外 &lt;strong&gt;『白賀正』&lt;/strong&gt;，还有罗勒调味的 &lt;strong&gt;『翠賀正』&lt;/strong&gt;、黑蒜墨鱼汁调味的 &lt;strong&gt;『黑賀正』&lt;/strong&gt; 和辣味的 &lt;strong&gt;『赤賀正』&lt;/strong&gt;，面里加水饺，大海苔，汤底偏咸。&lt;/p&gt;
&lt;p&gt;三宫站附近 日式居酒屋风格餐厅&lt;/p&gt;
&lt;p&gt;有点餐机 可中文 多种支付方式&lt;/p&gt;
&lt;h1 id=&#34;大阪&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#大阪&#34;&gt;#&lt;/a&gt; 大阪&lt;/h1&gt;
&lt;h2 id=&#34;北極星-心齋橋本店&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#北極星-心齋橋本店&#34;&gt;#&lt;/a&gt; 北極星 心齋橋本店&lt;/h2&gt;
&lt;p&gt;百年历史老店，可选鸡肉 / 火腿 / 蘑菇 / 牛肉 / 蟹肉&lt;strong&gt;蛋包饭&lt;/strong&gt;，辅以番茄酱汁（好像也有咖喱酱），可选 Topping 配菜炸物。是一份品质很不错的蛋包饭，但也仅此而已了。&lt;/p&gt;
&lt;p&gt;不支持预定，门口 iPad 上取号后排队，日式居榻榻米风格餐厅&lt;/p&gt;
&lt;p&gt;有中文菜单，支持信用卡支付&lt;/p&gt;
&lt;h2 id=&#34;お好み鉄板酒場-どら十doraju&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#お好み鉄板酒場-どら十doraju&#34;&gt;#&lt;/a&gt; お好み鉄板酒場 どら十（Doraju）&lt;/h2&gt;
&lt;p&gt;小巷子里的热门&lt;strong&gt;大阪烧&lt;/strong&gt;小作坊，仅有两名店员，样本观察顾客中国人居多，看不懂菜单的都点 MIX 大阪烧。也有蛋包饭、炒面、和牛、炸物烤物小吃等。入座必须要点一杯饮料。大阪烧做的确实不错，可选内料，表皮非常酥脆，内馅绵软柔密&lt;/p&gt;
&lt;p&gt;心斎橋駅 徒歩 3 分 日式居酒屋风格餐厅 座位少&lt;/p&gt;
&lt;p&gt;可在线预约 日文菜单 支持插入式信用卡&lt;/p&gt;
&lt;h2 id=&#34;銀座-篝拉麵-lucua大阪店&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#銀座-篝拉麵-lucua大阪店&#34;&gt;#&lt;/a&gt; 銀座 篝拉麵 LUCUA 大阪店&lt;/h2&gt;
&lt;p&gt;16、17 年的米其林推荐的网红&lt;strong&gt;拉面&lt;/strong&gt;，招牌鸡白汤拉面和花蛤牡蛎海鲜拉面。海鲜汤底有点鲜过头了，花蛤可能是熬汤后的产品，所以本身没有什么味道，牡蛎干货味道重，不是特别适合作为配菜。面条没有煮的很入味，面粉味还是非常明显的。Topping 是低温慢煮的鸡肉和猪肉，个人认为鸡肉没有处理的特别好，猪肉比较好吃。小碟是柚子皮和炸洋葱。总体而言除了汤底鲜甜，其他并不是很配得上他的价格和排队时间。&lt;/p&gt;
&lt;p&gt;大阪梅田 LUCUA 地下一层，排队久&lt;/p&gt;
&lt;p&gt;有中英文菜单，可使用信用卡和 suica&lt;/p&gt;
&lt;h1 id=&#34;京都&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#京都&#34;&gt;#&lt;/a&gt; 京都&lt;/h1&gt;
&lt;h2 id=&#34;やきとり大吉-堀川高辻店daikichi-horikawa-takatsuji&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#やきとり大吉-堀川高辻店daikichi-horikawa-takatsuji&#34;&gt;#&lt;/a&gt; やきとり大吉 堀川高辻店（Daikichi Horikawa Takatsuji）&lt;/h2&gt;
&lt;p&gt;非常物美价廉的日式烧鸟店，大部分鸡肉部位烧串都有，特殊部分没有（提灯什么的），单串价格都在十元以内。夫妻经营，人多时上菜稍慢。但是现场烤制味道好，厨师会英文可以聊天。还有烤饭团鸡肉汤和主食小吃，味道比较稀松平常。入座必须要点一杯饮料，送了一碗卷心菜沙拉。&lt;/p&gt;
&lt;p&gt;大宮駅附近，日式居酒屋风格餐厅，店内位置少&lt;/p&gt;
&lt;p&gt;有中英文菜单，可以支付宝&lt;/p&gt;
&lt;h2 id=&#34;smart-咖啡店&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#smart-咖啡店&#34;&gt;#&lt;/a&gt; Smart 咖啡店&lt;/h2&gt;
&lt;p&gt;少有的早餐店（虽然便利店和一般咖啡店也可以吃早饭）。法式吐司外层浸透了蛋液，烘焙出的焦化外壳非常酥脆，内部吐司绵软，有蜂蜜甜浆搭配，不会太甜（甜品的最高评价是不甜）。舒芙蕾松饼和各种三明治也做的不错，手工焦糖布丁口感密实。有各种饮品可点。二楼有提供午餐，经典的一些日式西餐。&lt;/p&gt;
&lt;p&gt;京都市役所前駅 徒歩 1 分 西式复古风格餐厅 环境氛围好&lt;/p&gt;
&lt;p&gt;英文菜单 多种支付方式 通常都会排队&lt;/p&gt;
&lt;h2 id=&#34;麺屋-猪一&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#麺屋-猪一&#34;&gt;#&lt;/a&gt; 麺屋 猪一&lt;/h2&gt;
&lt;p&gt;连续八年获得米其林推荐的拉面馆，汤头确实是醇厚鲜香的没话说，据说是不使用猪肉鸡肉等动物脂肪，仅用鲣鱼片提取的海鲜高汤，可以选择白酱油还是黑酱油汤底，黑酱油是二次熟成的，味道更厚一点。可以搭配柚子皮小碟解腻，面条几乎没有缺点，劲道入味。桌上有调味粉可选（黑七味粉 / 山椒粉 / 昆布等），Topping 可以选炙烤和牛或者温泉蛋等。有丼饭和烧麦小吃可选。&lt;/p&gt;
&lt;p&gt;京都河原町駅 徒歩 6 分 日式风格餐厅&lt;/p&gt;
&lt;p&gt;京都有两家店 只接受现场排队 店里不能随便拍照 只能拍食物 甚至有周边衣服和料理包卖 排队久&lt;/p&gt;
&lt;h2 id=&#34;maccha-house-抹茶館-京都清水産寧坂&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#maccha-house-抹茶館-京都清水産寧坂&#34;&gt;#&lt;/a&gt; MACCHA HOUSE 抹茶館 京都清水産寧坂&lt;/h2&gt;
&lt;p&gt;浅尝了一下宇治抹茶提拉米苏，最底下是抹茶戚风蛋糕，中间层起司内馅，上面撒抹茶粉。蛋糕被浸泡的有点潮比较影响口感，但整体内馅和抹茶的味道都是极好的，很香，不甜！最高评价。但其实在二三年坂商业街的抹茶甜点比比皆是，口味应该大差不差。&lt;/p&gt;
&lt;p&gt;巴士『清水道』站下车步行 6 分钟 日式庭院风格甜品店&lt;/p&gt;
&lt;p&gt;在日本拥有 7 家门店，有英文菜单，多种支付方式&lt;/p&gt;
&lt;h2 id=&#34;sushitetsu&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#sushitetsu&#34;&gt;#&lt;/a&gt; Sushitetsu&lt;/h2&gt;
&lt;p&gt;京阪三条駅 徒歩 5 分 日式风格餐厅&lt;/p&gt;
&lt;p&gt;有中英文菜单 支持信用卡 现场排队需要先门口填名字再排队&lt;/p&gt;
</content>
        <category term="旅行日志" scheme="http://example.com/categories/travel/" />
        <category term="日本跨年行" scheme="http://example.com/categories/travel/%E6%97%A5%E6%9C%AC%E8%B7%A8%E5%B9%B4%E8%A1%8C/" />
        <category term="旅行" scheme="http://example.com/tags/%E6%97%85%E8%A1%8C/" />
        <category term="唯有美食与爱不可辜负" scheme="http://example.com/tags/%E5%94%AF%E6%9C%89%E7%BE%8E%E9%A3%9F%E4%B8%8E%E7%88%B1%E4%B8%8D%E5%8F%AF%E8%BE%9C%E8%B4%9F/" />
        <updated>2024-02-03T16:00:00.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/travel/japan/route/</id>
        <title>15天9城特种兵行程总结</title>
        <link rel="alternate" href="http://example.com/travel/japan/route/"/>
        <content type="html">&lt;h1 id=&#34;關西&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#關西&#34;&gt;#&lt;/a&gt; 關西&lt;/h1&gt;
&lt;p&gt;⌀ 1.21 神戶 DAY1&lt;/p&gt;
&lt;p&gt;厦门高崎机场 --&amp;gt; 大阪关西机场&lt;/p&gt;
&lt;p&gt;⌀ 1.22 大阪 DAY2 市內景點走走&lt;/p&gt;
&lt;p&gt;⌀ 1.23 大阪 DAY3 環球影城？？or 機動&lt;/p&gt;
&lt;p&gt;⌀ 1.24 京都 DAY4 市內走走&lt;/p&gt;
&lt;p&gt;⌀ 1.25 京都 DAY5 市周圍走走？ 可以嵐山 或者宇治&lt;/p&gt;
&lt;p&gt;⌀ 1.26 奈良 DAY6&lt;/p&gt;
&lt;p&gt;⌀ 1.27 名古屋 DAY7 真不一定去吧 可以換箱根或者鐮倉？或者加到東京去&lt;/p&gt;
&lt;h1 id=&#34;關東&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#關東&#34;&gt;#&lt;/a&gt; 關東&lt;/h1&gt;
&lt;p&gt;⌀ 1.28 富士山 DAY1&lt;/p&gt;
&lt;p&gt;⌀ 1.29 東京 DAY2 淺草寺 晴空塔 秋葉原 新宿歌舞町 天空樹&lt;/p&gt;
&lt;p&gt;⌀ 1.30 東京 DAY3 東京塔 明治神宮 代代木公園 澀谷 sky 穿插&lt;/p&gt;
&lt;p&gt;⌀ 1.31 東京 DAY4 機動 下午或晚上需要到達坐船點或者飛機點&lt;/p&gt;
&lt;h1 id=&#34;北海道&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#北海道&#34;&gt;#&lt;/a&gt; 北海道&lt;/h1&gt;
&lt;p&gt;⌀ 2.1 札幌 DAY1 市中心走景點：圆山动物园→北海道神宫→白色恋人工厂→JR 塔展望室 T38 (夜景)→  狸小路 → 二条市场→札幌电视塔（大通公园 / 札幌钟楼）→ 中岛公园（或头大佛）→ 藻岩山展望台 (夜景)&lt;/p&gt;
&lt;p&gt;⌀ 2.2 札幌 DAY2 找個交通好一點的地方滑雪 酒店可不變 （19 號來的人該走了）&lt;/p&gt;
&lt;p&gt;⌀ 2.3 小樽 DAY3 市中心走 可以住小樽或者札幌 情懷散步&lt;/p&gt;
&lt;p&gt;⌀ 登別 DAY4&lt;/p&gt;
&lt;p&gt;⌀ 函館 DAY5&lt;/p&gt;
</content>
        <category term="旅行日志" scheme="http://example.com/categories/travel/" />
        <category term="日本跨年行" scheme="http://example.com/categories/travel/%E6%97%A5%E6%9C%AC%E8%B7%A8%E5%B9%B4%E8%A1%8C/" />
        <category term="旅行" scheme="http://example.com/tags/%E6%97%85%E8%A1%8C/" />
        <updated>2024-02-03T16:00:00.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/projects/punch_go/</id>
        <title>基于以太坊的『Punch Go』去中心化应用(DAPP)</title>
        <link rel="alternate" href="http://example.com/projects/punch_go/"/>
        <content type="html">&lt;h1 id=&#34;背景介绍&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#背景介绍&#34;&gt;#&lt;/a&gt; 背景介绍&lt;/h1&gt;
&lt;p&gt;本项目的目标是开发一个去中心化应用 (DAPP) 平台，以促进打孔目标发起者和拥有类似目标的个人之间的联系。目标发起者将通过引入与目标相关的共享价值、设置参与存款要求和指定活动截止日期来发起打孔活动。平台用户可以访问所有正在进行或已经完成的打孔活动。如果活动正在进行，用户可以通过存款指定数量的加密货币来加入。为了保持在打孔活动中的积极性，用户必须每天打孔；如果失败，将导致他们的存款被没收。在每次打孔活动结束时，所有存款将平均分配给每天坚持打孔的用户。&lt;/p&gt;
&lt;p&gt;我们的项目旨在建立目标发起者和目标追逐者之间的联系，使我们的用户能够在获得金钱奖励的同时实现目标；同时，那些缺乏毅力的人将面临后果。&lt;/p&gt;
&lt;h1 id=&#34;创意来源&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创意来源&#34;&gt;#&lt;/a&gt; 创意来源&lt;/h1&gt;
&lt;p&gt;从项目一开始，我们就想了解更多关于如何构建 DAPP 的知识。我们首先想要复制一个众筹 DAPP。但在那个众筹项目中，我们创新地增加了在众筹截止日期前申请使用资金的功能。发起人可以在他认为需要的时候申请。但他必须填写一份申请表，并解释这笔资金的用途。然后，赞助者可以在使用详情部分查看此应用程序。发起人可以选择同意或拒绝发起人的申请。如果商定的总百分比超过 50%，那么发起者可以获得这笔资金供他使用。&lt;/p&gt;
&lt;p&gt;然后，我们有了 “打拳” 的想法。这是因为我们在准备实习或全职工作面试时经常需要练习 LeetCode。但由于人们有惯性，我们不能坚持练习很长时间。更具体地说，我们中的许多人可能都有这样的情况：我们有一个重要的目标要实现，也许用 LeetCode 更好地编程，或者像外国人一样用托福练习英语，但只是没有足够的内在动力来实现它。在过去，许多新年计划由于缺乏自我控制而被放弃。所以，我们需要一些激励和惩罚。这就是我们的 “Punch Go” DAPP 旨在提供的。“打拳” 这个概念近年来一直是一个热门话题，一群人有一个共同的目标，并相互监督以实现这一目标。在区块链技术的帮助下，我们可以将打卡的想法推向更高的标准。在 “Punch Go” 的典型场景中，存在三个利益相关者：提出共同目标的项目发起人，拥有相同目标并愿意致力于此的一群人，以及将双方联系在一起的平台。&lt;/p&gt;
&lt;p&gt;之后，我们发现 “打卡” 与 “众筹” 有着非常紧密的内在联系。本质上，他们都是从参与者 (赞助商) 那里收钱，然后再进行再分配。在 “众筹” 中，资金被重新分配给发起人。但在 “打卡” 中，资金被重新分配给每一个坚持 “打卡” 活动的人。&lt;/p&gt;
&lt;p&gt;此外，我们建议必须增加一些 “打卡” 的监督机制。我们不能让用户的 “打卡” 立即得到同意，因为用户可能会作弊。因此，我们增加了 “批准” 和 “拒绝” 功能，以便用户监督其他人的 “打卡”。一旦 “打卡” 得到 50% 以上剩余参与者的认可，即为有效。幸运的是，这与我们在 “众筹” 系统中完成的实现是相似的。&lt;/p&gt;
&lt;h1 id=&#34;开发框架&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#开发框架&#34;&gt;#&lt;/a&gt; 开发框架&lt;/h1&gt;
&lt;h2 id=&#34;环境配置&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#环境配置&#34;&gt;#&lt;/a&gt; 环境配置&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;技术栈:&lt;/strong&gt; Nodejs + React + Solidity&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;前端 UI:&lt;/strong&gt; bootstrap&lt;/p&gt;
&lt;p&gt;要运行这个项目，您需要为这个 DAPP 设置基本环境。你应该安装 React + Web3 + npm + truffle。此外，您应该在 Edge 浏览器中安装 MetaMask。您还应该在 Edge 浏览器中安装 MetaMask Legacy Web3 扩展，以便我们的网站可以与区块链进行交互。&lt;/p&gt;
&lt;p&gt;注意：这里你可以使用 Edge 或 Firefox 浏览器来运行我们的项目，Chrome 不受支持，因为它不能安装 MetaMask Legacy Web3 扩展。&lt;/p&gt;
&lt;h2 id=&#34;启动步骤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#启动步骤&#34;&gt;#&lt;/a&gt; 启动步骤&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;使用 Ganache 导入 truffle-config.js&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/workspace.png&#34; alt=&#34;alt text&#34; title=&#34;Ganache设置&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;使用命令 “truffle migrate” 编译 solidity 的智能合约&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 Ganache 中找到部署的合同地址，并将该地址复制到 “client/src/eth/punch .js” 第 299 行地址变量中&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/contract2.png&#34; alt=&#34;alt text&#34; title=&#34;合约地址&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;使用 CMD 命令进入客户端目录 &amp;quot;cd client&amp;quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 npm 来安装依赖 &amp;quot;npm install&amp;quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;运行这个项目 &amp;quot;npm run start&amp;quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果运行成功，您可以在 “localhost:3000” 上找到我们的项目。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/home_page.png&#34; alt=&#34;home&#34; title=&#34;首页&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;功能介绍&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#功能介绍&#34;&gt;#&lt;/a&gt; 功能介绍&lt;/h1&gt;
&lt;p&gt;如前所述，第一个实现的想法是一个众筹应用程序，它支持用户发起融资或参与特定的众筹项目。当一个特定的资金发起者想要花费这笔钱时，需要一半的参与者批准交易，项目发起者才能真正花费所需的金额。&lt;/p&gt;
&lt;p&gt;在我们建立了这个众筹平台之后，我们提出了另一个名为 “Punch Go” 的想法来帮助人们完成日常任务。考虑到众筹 DAPP 更像是初学者的启动项目，我们决定用这个新想法来真正动手。背后的理论是非常相似的。在本节中，我们将重点讨论第二个想法的功能。&lt;/p&gt;
&lt;p&gt;首先，在我们进入细节之前，需要对 “Punch Go” 的整体情况进行简要介绍。我们的应用程序，顾名思义，是帮助人们摆脱拖延症的监督者。这是一个人们可以发起或参与打拳活动的平台。当然，参加这样的活动需要一些钱来激励个人每天打卡，但如果参与者达到了他们设定的目标，他们就会得到奖励，分享池中的存款。现在我们来看一下详细的功能。&lt;/p&gt;
&lt;p&gt;在我们的应用程序的主页上，它显示了网络上所有活动的概述，包括打孔活动的总数、已完成的打孔活动和正在进行的打孔活动。如果用户有兴趣，可以导出所有打孔活动的统计报表。此外，用户的账户地址将显示在页面的右上角，供用户查看和确认钱包中当前的加密货币账户。一旦用户在 MetaMask 中更改帐户，金额将立即在我们的前端更新。此外，还增加了搜索功能，以便用户可以找到任何记录的感兴趣的打孔活动。&lt;/p&gt;
&lt;p&gt;其次，启动器的最小功能单元是启动一个新的冲孔活动。在 “打孔发起” 一栏，用户可以填写自己的打孔活动信息，包括活动名称、主要目标、截止时间、参与金额等。将检查每条消息的有效性。一旦所有输入的信息都是有效的，发起者就可以确认这个新的活动，它将更新网络中部署的合约。应用程序将自动连接到 MetaMask，并扣除此类操作的 gas 费用。&lt;/p&gt;
&lt;p&gt;在 “All Punches” 部分中，记录中存储的每个活动都将显示为带有其名称和状态标记的块标记。通过点击 “查看详情”，将显示有关这些活动的所有具体信息。“查看详情” 面板包含发起人的信息，以及活动操作过程的必要信息，包括项目状态 (已完成或正在进行)，总保证金，参与本次打孔活动的总人数以及剩余参与者 (因为有些人可能会放弃)。如果您不是本次活动的发起者，会有一个 “我想参与” 按钮让您加入当前的活动。一旦你加入了一个活动，右上角会有一个绿色的打孔按钮，你可以在那里打孔。&lt;/p&gt;
&lt;p&gt;还有一个界面供用户检查与自己相关的活动。参与者可以在 “参加的出拳次数” 一栏查看出拳情况，以便监督自己参加的所有出拳的过程。发起者也可以在 “发起打孔” 中查看自己发起的活动信息，查看打孔活动情况。&lt;/p&gt;
&lt;p&gt;活动通常会在截止日期前结束，只要你完成了你设定的目标，你就会得到一份。但是，如果您在活动期间放弃，您的会议将提前结束，您将被从参与者名单中除名，以防止一些恶意投票。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/punch.png&#34; alt=&#34;&#34; title=&#34;日常打卡登记注册&#34;&gt;&lt;/p&gt;
&lt;p&gt;具体来说，有一种机制让参与者每天打卡。如上图所示，发起者可以提交一个包含打孔日期和打孔内容的表单。此时，项目详情页面将出现一个状态栏 (如下图所示)。&lt;br&gt;
。其他参与者可以根据是否同意而选择批准或拒绝打孔请求。一旦超过 50％的参与者同意这样的请求，你就成功打卡了。如果在一定时间内没有足够的人同意，该请求将被拒绝，该用户将被移出参与者列表。&lt;/p&gt;
&lt;p&gt;![](/assets/punch_go/0% approve.png&amp;gt;)&lt;/p&gt;
&lt;p&gt;![](/assets/punch_go/100% appove.png)&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/initiation_success.png&#34; alt=&#34;initiation success&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/response.png&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/punch_success.png&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/punch_go/response.png&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;效果展示&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#效果展示&#34;&gt;#&lt;/a&gt; 效果展示&lt;/h1&gt;
&lt;p&gt;在本部分中，我们将向您展示应用程序中的一些特定示例。整个主页如图 \ref {fig:home} 所示，展示了账号地址和搜索功能。显示总览统计信息，并显示进程速率。&lt;/p&gt;
&lt;p&gt;我们假设有人想要建立一个新的冲孔活动，如图 \ref {fig:Initiate a punch} 所示。应用程序将给出如图 \ref {fig:initiation success} 所示的响应。因此，将设置一个名为 “leetcode” 的冲床，其状态为 “正在进行”，其参与费用和截止日期见图 \ref {fig:activity detail}。当有人有相同的目标，想要加入这样的活动来提高自己时，“我想参与” 按钮位于页面的左下角。用户进入冲床后，通过图 \ref {fig:Punch detail} 中的 “冲床” 功能完成每天的任务并提交内容进行验证。其他用户可以选择同意或拒绝某人的 “工作”，就像图 \ref {fig:Punch-checking} 一样。如果您选择批准穿孔内容，将出现图 \ref {fig:approve respond} 的响应。只要超过 50％的人同意你的 punch，当天的任务就可以确定了。以便参与者可以在第二天继续打孔活动。所有的冲孔都可以在图 \ref {fig:All punches} 上看到。作为发起人，您可以管理您的活动页面 “发起的拳头”，如图 \ref {fig:activity initiated} 所示。而对于参与者，图 \ref {fig:activity participated} 中的信息将为您提供所参加活动的一致更新。&lt;/p&gt;
&lt;h1 id=&#34;结论及未来工作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#结论及未来工作&#34;&gt;#&lt;/a&gt; 结论及未来工作&lt;/h1&gt;
&lt;p&gt;我们项目的意义在于将拥有相同目标的人们联系在一起。我们使用 Node.js, React 和 Solidity 开发了一个 DAPP 平台，使不同的人之间能够进行共享价值的交流。平台功能包括显示正在进行的冲孔活动进度和完成的冲孔目标的仪表板，启动冲孔活动并提供发起者输入信息，冲孔活动完成后向目标实现者发送费用。&lt;/p&gt;
&lt;p&gt;对于未来的工作，我们的目标是增加功能，使我们的平台更容易使用，并具有更丰富的功能。完善监督机制，加强制度安全是我们的首要任务。解决活动被恶意方控制的风险对于保护其他用户非常重要。我们计划为那些认为自己的打卡被拒绝时应该被批准的用户增加申诉机制的功能。此外，给别人打卡 “拒绝” 标签的用户也应该在我们 DAPP 的未来版本中说明他们的理由。另外，我们计划增加活动发起者每天设置一些任务，要求参与者打卡的功能。&lt;/p&gt;
</content>
        <category term="科研项目" scheme="http://example.com/categories/projects/" />
        <category term="区块链" scheme="http://example.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/" />
        <category term="开发" scheme="http://example.com/tags/%E5%BC%80%E5%8F%91/" />
        <updated>2022-05-10T16:00:00.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/projects/stream_processing/</id>
        <title>用深度强化学习实时预测和交易加密货币</title>
        <link rel="alternate" href="http://example.com/projects/stream_processing/"/>
        <content type="html">&lt;div class=&#34;note info&#34;&gt;
&lt;p&gt;可以在此处找到项目的原代码 &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL01pcmFjbGVMaW56enovS2Fma2FSZWFsVGltZUNyeXB0b2N1cnJlbmN5&#34;&gt;📍链接&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1 class=&#34;danger&#34; id=&#34;背景介绍~~瞎鸡儿凑字数~~&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#背景介绍~~瞎鸡儿凑字数~~&#34;&gt;#&lt;/a&gt; 背景介绍～～(瞎鸡儿凑字数)~~&lt;/h1&gt;
&lt;h2 id=&#34;为什么要用强化学习&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为什么要用强化学习&#34;&gt;#&lt;/a&gt; 为什么要用强化学习？&lt;/h2&gt;
&lt;p&gt;股票交易是一种优先考虑短期利润而不是长期回报的投资形式。因此，在进行股票交易时，有必要具备专业知识。大多数股票投资者都知道基本面分析中最常用的财务数据。在此分析的基础上，他们可以进行量化交易。&lt;/p&gt;
&lt;p&gt;近年来，越来越多的公司试图利用人工智能来建立&lt;span class=&#34;red&#34;&gt;机器学习模型&lt;/span&gt;，以此来改进他们的交易策略。&lt;/p&gt;
&lt;p&gt;在我们的项目中，我们在股票市场的背景下，建立了&lt;span class=&#34;red&#34;&gt;强化学习模型&lt;/span&gt;，对比特币的交易进行实时决策。&lt;/p&gt;
&lt;p&gt;股票市场包括历史价格序列和走势，可以看作是一个复杂的环境。我们的目标是培养一个能自己对买入和卖出股票做决定的代理单元。因此，&lt;span class=&#34;red&#34;&gt;强化学习算法&lt;/span&gt;可以有效地解决这个问题。&lt;/p&gt;
&lt;p&gt;强化学习的目的是优化累积的未来奖励信号，以便为序列选择问题制定适当的策略。在研究了部分金融投资组合管理问题的深度强化学习框架后，发现部分 Q 学习算法，如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;red&#34;&gt;异步优势演员 - 评论家算法&lt;/span&gt; (Asynchronous Advantage Actor-Critical, A3C)&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;red&#34;&gt;信赖域策略优化算法&lt;/span&gt; (Trust Region Policy Optimization, TRPO)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在某些条件下存在明显高估的动作价值，继而影响最终的性能。相比之下，&lt;span class=&#34;red&#34;&gt;DQN&lt;/span&gt; (Deep Q-network) 通过将 Q 学习与深度神经网络相结合来解决这些问题，不仅减少了观察到的高估值，而且在一些博弈理论上显著地提高了性能。&lt;/p&gt;
&lt;h2 id=&#34;为什么要用流处理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为什么要用流处理&#34;&gt;#&lt;/a&gt; 为什么要用流处理&lt;/h2&gt;
&lt;p&gt;在传统的投资组合管理问题中使用流处理的原因是为了解决两个重要的量化交易问题:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据数量上的短缺&lt;/li&gt;
&lt;li&gt;数据本身质量低&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;金融数据信息处理需要从海量的噪声中提取有意义的数据。由于金融市场上存在大量的噪音，人们最朴素期待的结果就是自己做出的决策事正确决策的概率大于 50%。&lt;/p&gt;
&lt;p&gt;但事实总是不尽人意，通常来说，基于以往有限样本的旧数据进行的预测研究往往很难达到令人接受的程度。&lt;/p&gt;
&lt;p&gt;故，金融和经济学领域的强化学习研究通常不会在 “大数据” 背景下进行。&lt;/p&gt;
&lt;p&gt;金融统计分析与一般的宏观经济学一样，本质上是一门时间序列学科，实时预测更有意义。在回报预测的情况下，我们总是可以创建更大更好的预测数据集。然而，我们感兴趣的结果变量的观测数量是有限的。每日蜡烛数据不足以训练金融领域的强化学习模型。只有时间的流逝才能产生有关股票回报的新数据。如果没有足够的训练集，我们无法可靠地预测复杂的模型。&lt;/p&gt;
&lt;p&gt;为了解决上述问题，使我们的系统具有更现实的意义和更多的商业价值，我们构建了一个集成深度强化学习模型和 Kafka 流处理方法的高效结构来获取和处理实时股票数据。我们还利用 15 个已实现的实时数据对结构中的数据进行预处理，生成技术指标。此外，通过对新数据的有效性检验，对所设计的系统进行了改进。具体来说，如果当前数据值与前一个数据值的差值不大于 3%，则判定新到达的数据有效。如果不是，当前数据将被前一个数据的值所替换。我们基于 Kafka 流处理的系统的另一大优势是它可以通过几个加密货币公司检索信息，因此它有可能同时处理不同的多种加密货币数据。在这里，我们通过向代理指定主题来获取比特币数据。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/stream_processing/image.png&#34; alt=&#34;&amp;quot;深度强化学习(DRL)模型&amp;quot;&#34; title=&#34;深度强化学习(DRL)模型&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;流处理操作流程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#流处理操作流程&#34;&gt;#&lt;/a&gt; 流处理操作流程&lt;/h1&gt;
&lt;p&gt;一旦我们导出了经过训练的强化学习模型，我们就可以通过一系列技术工具构建应用程序来获得实时预测结果。 如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/stream_processing/flowchart.png&#34; alt=&#34;&amp;quot;总体技术栈流程图&amp;quot;&#34; title=&#34;总体技术栈流程图&#34;&gt;&lt;/p&gt;
&lt;p&gt;整个项目流程图可以简单地分为几个部分，包括&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据采集与流数据转换&lt;/li&gt;
&lt;li&gt;流数据处理&lt;/li&gt;
&lt;li&gt;流数据预测&lt;/li&gt;
&lt;li&gt;数据可视化&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;环境配置准备&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#环境配置准备&#34;&gt;#&lt;/a&gt; 环境配置准备&lt;/h2&gt;
&lt;p&gt;建议使用 Anaconda 创建虚拟环境&lt;br&gt;
 &lt;code&gt;conda create -n your_env_name python=x.x&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;keras==2.3.1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensorflow==1.14.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pandas==0.24.2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;numpy==1.16.1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tqdm==4.24.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;docopt==0.6.2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;coloredlogs==10.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;jupyterlab==1.0.1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;altair==4.0.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;seaborn==0.9.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cryptocompare&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;matplotlib&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;pip install -r requirement.txt&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;流处理软件初始化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#流处理软件初始化&#34;&gt;#&lt;/a&gt; 流处理软件初始化&lt;/h2&gt;
&lt;div class=&#34;note warning&#34;&gt;
&lt;p&gt;这个项目是在个人电脑上运行的 demo，Windows 11 系统。实际运行可能在云平台或虚拟机 Linux 上效果更加，配置操作相应变化。&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Kafka 依赖 ZooKeeper 作为分布式系统提供协调服务的工具，在启动 Kafka 服务前需要先启动 ZooKeeper 服务。&lt;br&gt;
新版本 Kafka 内置了 ZooKeeper 服务（Kafka 2.8 之后），所以我们可以有两种 ZooKeeper 的启动方式&lt;br&gt;
一种是单独下载 ZooKeeper，然后配置环境变量、启动服务&lt;br&gt;
第二种是启动 Kafka 内置的 ZooKeeper 服务&lt;/p&gt;
&lt;h3 id=&#34;单独搭建-zookeeper-环境并启动服务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#单独搭建-zookeeper-环境并启动服务&#34;&gt;#&lt;/a&gt; 单独搭建 ZooKeeper 环境并启动服务&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;官网下载：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96b29rZWVwZXIuYXBhY2hlLm9yZy8=&#34;&gt;https://zookeeper.apache.org/&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;选择自己需要的版本，下载压缩包（本项目是 3.6.3 版本）&lt;/li&gt;
&lt;li&gt;将压缩包存放在磁盘某位置，路径无中文&lt;/li&gt;
&lt;li&gt;在 ZooKeeper 的解压缩目录中，找到 conf 文件夹，该文件夹包含了 ZooKeeper 的配置文件。复制 “zoo_sample.cfg&amp;quot;这个文件，重命名为&amp;quot;zoo.cfg”，修改相应配置项，如
&lt;ul&gt;
&lt;li&gt;dataDir：指定 ZooKeeper 存储数据的目录，默认为 /tmp/zookeeper&lt;/li&gt;
&lt;li&gt;dataLogDir：指定 ZooKeeper 存储日志的目录&lt;/li&gt;
&lt;li&gt;clientPort：指定客户端连接到 ZooKeeper 服务器的端口号，默认为 2181&lt;/li&gt;
&lt;li&gt;tickTime：指定 ZooKeeper 服务器之间的心跳间隔时间（以毫秒为单位），默认为 2000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;创建需要的 data 和 logs 文件夹在相应目录，也可以在 cmd 命令行里全局指定地址，如&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&#34;highlight shell&#34;&gt;&lt;figcaption&gt;&lt;span&gt;命令行提示符 command:(&#34;[root@localhost] $&#34;:1)&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;set ZOOKEEPER_LOGS_PATH=C:\tmp\zookeeper&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;编辑 path 系统变量，添加路径 &lt;code&gt;%ZOOKEEPER_HOME%\bin&lt;/code&gt; ，ZOOKEEPER_HOME 为文件夹路径&lt;/li&gt;
&lt;li&gt;打开 cmd 命令窗口，输入 zkServer，启动 ZooKeeper 服务。关闭窗口则结束服务&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;下载kafka&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#下载kafka&#34;&gt;#&lt;/a&gt; 下载 Kafka&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;官网下载：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL2thZmthLmFwYWNoZS5vcmcvZG93bmxvYWRz&#34;&gt;http://kafka.apache.org/downloads&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;选择自己需要的版本，下载压缩包（本项目是 2.12-3.1.0 版本）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;启动kafka内置的zookeeper服务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#启动kafka内置的zookeeper服务&#34;&gt;#&lt;/a&gt; 启动 Kafka 内置的 ZooKeeper 服务&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;将压缩包存放在磁盘某位置，路径无中文，新建 data 文件夹&lt;/li&gt;
&lt;li&gt;进入 &amp;quot;config&amp;quot; 目录，用编辑软件打开 &amp;quot;zookeeper.properties&amp;quot; 文件，修改 &amp;quot;dataDir&amp;quot;&lt;/li&gt;
&lt;li&gt;打开 cmd 命令窗口，进入 Kafka 解压包根目录，输入命令行启动 Kafka 内置的 ZooKeeper 服务。关闭 cmd 窗口即关闭服务&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/stream_processing/zookeeper.png&#34; alt=&#34;Start and initialize Zookeeper&#34; title=&#34;ZooKeeper启动成功&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;启动kafka&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#启动kafka&#34;&gt;#&lt;/a&gt; 启动 Kafka&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;在 Kafka 解压包根目录下新建 &amp;quot;kafka-logs&amp;quot; 文件夹&lt;/li&gt;
&lt;li&gt;进入 &amp;quot;config&amp;quot; 目录，用编辑软件打开 &amp;quot;server.properties&amp;quot; 文件，找到 &amp;quot;log.dirs&amp;quot; 配置，将其路径设置为我们新建的 &amp;quot;kafka-logs&amp;quot; 目录的路径。如果有修改 ZooKeeper 服务的默认端口或 ip, 可以同时编辑 “zookeeper.connect”，更改 ZooKeeper 服务的 ip 和端口号配置&lt;/li&gt;
&lt;li&gt;打开 cmd 命令窗口，进入 Kafka 解压包根目录下，输入命令行，启动 Kafka。关闭 cmd 窗口即关闭服务&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;.\bin\windows\kafka-server-start.bat .\config\server.properties&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/stream_processing/kafka.png&#34; alt=&#34;Start and initialize Kafka&#34; title=&#34;Kafka启动成功&#34;&gt;&lt;/p&gt;
&lt;details class=&#34;danger&#34;&gt;&lt;summary&gt;可能存在的报错&lt;/summary&gt;&lt;div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;端口占用&lt;br&gt;
可以用  &lt;code&gt;netstat -ano | findstr 2181&lt;/code&gt;  找到占用端口的 pid，然后用  &lt;code&gt;taskkill /f /pid pid号&lt;/code&gt;  关闭即可&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kafka 执行完就 shutting down&lt;br&gt;
 可能是 Kafka 集群 id 跟元数据 &amp;quot;meta.properties&amp;quot; 中存储的不一致，导致启动失败。只需要将 Kafka 配置文件 &amp;quot;server.properties&amp;quot; 中 &amp;quot;log.dirs&amp;quot; 配置的 &amp;quot;kafka-logs&amp;quot; 目录下的文件全部删除，重新执行 Kafka 的启动命令即可。ZooKeeper 同理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;timeindex.cleaned 另一个程序正在使用此文件，进程无法访问&lt;br&gt;
可能由于非正常关闭 Kafka, 导致其无法完成对日志文件完成解锁。将 &amp;quot;kafka-logs&amp;quot; 路径下的文件全部删除重启即可&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目录层级太深或者是目录名字太长可能导致启动失败&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/details&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/stream_processing/producer.png&#34; alt=&#34;Producer –&amp;gt; Kafka&#34;&gt;&lt;br&gt;
&lt;img data-src=&#34;/assets/stream_processing/consumer.png&#34; alt=&#34;Consumer –&amp;gt; Spark Streaming&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;note danger&#34;&gt;
&lt;p&gt;Kafka 和 Spark Dstream 之间的版本问题:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark 2.4 之后，没有针对 Spark Streaming 的更新（已弃用），这意味着两者之间没有 API。&lt;br&gt;
 &lt;code&gt;from pyspark.streaming.kafka import KafkaUtils&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Structured Streaming 成为主流流处理数据结构&lt;/li&gt;
&lt;li&gt;需要一个配置文件用于连接 Kafka 和 Spark Streaming，他的版本也关系到能否起到兼容效果。&lt;/li&gt;
&lt;li&gt;此外还有需要注意的有
&lt;ul&gt;
&lt;li&gt;Py4J 的兼容性问题&lt;/li&gt;
&lt;li&gt;Java JDK 的兼容性问题&lt;/li&gt;
&lt;li&gt;高版本 Python 的兼容性问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/stream_processing/config.png&#34; alt=&#34;config&#34;&gt;&lt;/p&gt;
&lt;p&gt;一开始，使用 &lt;span class=&#34;red&#34;&gt;Cryptocompare API&lt;/span&gt;，某些加密货币的实时价格将来自开源以及其他附加信息。 当我们启动并初始化多个 Kafka 生产者时，不同的价格信息将按其不同主题（其加密货币名称）分隔并存储在 Broker 上。 数据类型将从原始字典打包成字符串。 顾名思义，经纪人充当生产者和消费者之间信息的渠道。 在这个过程中，所有这些组件都需要向 Zookeeper 注册。 Kafka 集群使用 Zookeeper 来管理 Kafka 配置并选举领导者。 所有主题和代理之间的映射由 Zookeeper 维护。 而当 Consumer Group 发生变化时，就会进行重新平衡。 由于我们仅在一台 PC 上运行演示，因此未应用分区配置。&lt;/p&gt;
&lt;p&gt;同时，Spark 作为 Consumer 获取 Broker 中的数据并转化为 Dstream。 假设有几个用时间序列号标记的 Dstream。 为了消除由于我们获取高频数据而产生的异常干扰，我们设置了一个过滤操作来选择合格的候选者。 如图 \ref {fig:so} 所示，原始 Dstream 被复制，以便一旦有新数据进来，就应该与前一个数据进行比较。 如果它们之间的值差小于 3&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;%&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\%&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.80556em;vertical-align:-0.05556em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;%&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，则可以允许进行进一步的操作，否则将被弃用。 经过初步选择后，对 Dstream 进行窗口操作。 窗口长度设置为 15 和 1 步幅。 可以看作是一个队列。 一旦有新数据进来，旧记录就会消失。 一定程度上解决了数据短缺的问题。 更多的输入数据可能会提高模型的预测性能。 然后，处理后的数据将被推送回 Broker，成为一个新的主题。&lt;/p&gt;
&lt;p&gt;随后，该模型将从 Broker 获取数据作为新的 Consumer。 由于模型相对复杂，我们在利用模型进行预测时并没有完全采用流式处理。 我们没有使用 Spark MLlib 中的操作。 相反，从 Broker 中提取的数据将更改为 DataFrame 并由模型以正常方式读取。 最后，结果会形成折线图显示在前端页面。&lt;/p&gt;
&lt;p&gt;此外，还初始化了另一组 Consumer 来代表不同加密货币的信息，以便在网站上显示价值。 消费者将数据类型从字符串恢复到原始字典。 重新整合字典的键后，将通过 WebSocket 传输到前端 HTML。 最后解析为 Json 格式进行可视化。&lt;/p&gt;
&lt;figure class=&#34;highlight shell&#34;&gt;&lt;figcaption&gt;&lt;span&gt;命令行提示符 command:(&#34;[root@localhost] $&#34;:1-5)&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;set ZOOKEEPER_LOGS_PATH=C:\tmp\zookeeper&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;set KAFKA_LOGS_PATH=C:\tmp\kafka-logs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;set KAFKA_PATH=F:\kafka\kafka_2.12-3.1.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;set ANACONDA_PATH=F:\anaconda3\envs\stream&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;set THIS_PATH=C:\Users\81051\Desktop\code&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img data-src=&#34;/assets/stream_processing/stream_operations.png&#34; alt=&#34;&#34; title=&#34;流处理模块示意&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;media-container&#34;&gt;&lt;div class=&#34;player&#34; data-type=&#34;video&#34; data-src=&#39;[{&#34;name&#34;:&#34;demo&#34;,&#34;url&#34;:&#34;/assets/stream_processing/demo.mp4&#34;}]&#39;&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h1 id=&#34;还能做的一些事情&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#还能做的一些事情&#34;&gt;#&lt;/a&gt; 还能做的一些事情&lt;/h1&gt;
&lt;p&gt;总之，我们的应用 DRL 模型被证明在加密货币交易中是有效的，我们还利用 Kafka 流处理技术结合 Spark 来访问实时数据并实时处理它们。&lt;/p&gt;
&lt;p&gt;至于以后的工作，还有很多可以做的推广。因为它可能涉及到很多我们没有经验的其他技术工具。尽管调查正在进行，但我们不会在这里讨论任何细节。相反，一些高层次的想法会被谈论，一些解释可能不准确和适当，道歉。&lt;/p&gt;
&lt;p&gt;首先，所有的强化学习操作将被移植到 Spark Streaming。利用 Keras API 和 Spark MLlib，我们可以定义转换、管道和特性，从而完全以 Streaming 的形式实现预测功能。此外，还可以使用其他工具来更好地在 Spark 中呈现模型。例如，Analytics Zoo 是一个在 Spark 上运行 TensorFlow 的平台。与基础设施、Spark 数据结构和管道集成。BigDL 是一个开源的分布式深度学习框架。从而实现分布式模型训练和评估。&lt;/p&gt;
&lt;p&gt;其次，虽然我们尝试用 Kafka 和 Spark 来重现整个管道过程，但是分布式属性，这个最大的优势和特点，并没有表现出来。原因主要是我们只在一台计算机上部署应用程序。&lt;/p&gt;
&lt;p&gt;为了实现分布式的想法，在云平台托管应用程序将是一个不错的选择。在此之前，Docker 可以设置一个容器来打包应用程序。而 Kubernetes 会更好，因为它是部署大规模分布式应用程序的平台。它可以管理一堆主机和节点。在每个节点中，它运行许多独立的 pod (容器集)，这些 pod 可以实现我们应用程序的组件，如数据库，网站服务器。一旦我们将 Kubernetes 部署在某个平台上，比如 Amazon EKS 或 Google GKE，它就可以创建一个集群来组织我们设置的所有节点，并构建一个控制面板来管理它们。在一定程度上实现了分布式特性。节点可以执行不同的指令。例如，不同节点可以异步处理不同类型的加密货币，从而减少数据更新的延迟。另一方面，多个节点可以继续运行训练过程，并通过实时性持续优化模型的性能。在不影响前端网页正常使用的情况下，逐步更换旧机型。当任何其他用户想要查看特定加密货币的预测结果时，他可以访问特定的主机来获取它们。Kafka 的分区配置也可以在这样的多个节点中使用。&lt;/p&gt;
</content>
        <category term="科研项目" scheme="http://example.com/categories/projects/" />
        <category term="强化学习" scheme="http://example.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" />
        <category term="流处理" scheme="http://example.com/tags/%E6%B5%81%E5%A4%84%E7%90%86/" />
        <category term="Kafka" scheme="http://example.com/tags/Kafka/" />
        <category term="Zookeeper" scheme="http://example.com/tags/Zookeeper/" />
        <category term="Spark" scheme="http://example.com/tags/Spark/" />
        <updated>2022-05-07T16:00:00.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/travel/xinjiang/xinjiang/</id>
        <title>跨越山海|新疆自驾毕业旅行</title>
        <link rel="alternate" href="http://example.com/travel/xinjiang/xinjiang/"/>
        <content type="html"></content>
        <category term="旅行日志" scheme="http://example.com/categories/travel/" />
        <category term="旅行" scheme="http://example.com/tags/%E6%97%85%E8%A1%8C/" />
        <updated>2021-06-19T16:00:00.000Z</updated>
    </entry>
</feed>
