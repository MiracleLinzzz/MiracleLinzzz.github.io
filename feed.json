{
    "version": "https://jsonfeed.org/version/1",
    "title": "自是白衣卿相的博客",
    "subtitle": null,
    "icon": "http://example.com/images/favicon.ico",
    "description": null,
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2024/02/24/neural_network/transformer/",
            "url": "http://example.com/2024/02/24/neural_network/transformer/",
            "title": "Transformer 备忘录",
            "date_published": "2024-02-23T16:00:00.000Z",
            "content_html": "<ol>\n<li>\n<p>为什么选择 Transformer<br>\nNLP 任务需要编码器抽取上下文的特征<br>\n上下文的语义很重要，每个词的语义和上下文强相关<br>\n方向<br>\n RNN 只能对句子进行单向的编码<br>\n CNN 只能对短句子进行编码<br>\n Transformer 可以双向编码，也抽取长距离的特征<br>\n顺序（词的位置变换了会产生不同的意思）<br>\n速度<br>\n RNN 无法并行处理序列，其他都行</p>\n</li>\n<li>\n<p>多头自注意力模块<br>\n首先对输入进行 projection，得到 QKV 三个矩阵<br>\n（tf 对输入进行了降维 (B, L, D) -&gt; (B<em>L, D)）<br>\n初始化三个 dense 层 (B</em>L, D) -&gt; (B<em>L, N</em>H) N 为 attention 模块的数量，H 为长度<br>\n为什么要在这个进行投影呢？<br>\n若不投影，在之后的注意力模块中，相同的 Q 和 V 会进行点积，使得 attention 矩阵对角线的分数特别高（自己和自己的分数？），每个词的注意力都在自己身上，无法获得上下文的关系。所以需要将 QKV 投影到不同的空间中，增加多样性。</p>\n<p>之后进行 reshape, (B<em>L, N</em>H) -&gt; (B, N, L, H)<br>\n 为什么要用多注意力头呢？<br>\n希望不同的注意力头学到不同的特征，和 CNN 里的 multi-channel 类似</p>\n<p>多不同的注意力头进行点积、转置<br>\n为什么要用乘法呢？（为什么不用加性 attention 呢？）<br>\n在 GPU 的场景下，矩阵乘法的效率更高，随着 D 的增大，加性 attention 的效果会更好<br>\n为什么要除以√D 呢？<br>\n两个的矩阵相乘之后方差会变大，使得有些词注意力很大有些很小，经过 softmax 之后再求导会导致梯度很小，不利于优化，除了之后可以平滑一下。e.g. N (0, √d)*N (0, √d) = N (0, d) -&gt; / √d -&gt; N (0, 1)。</p>\n<p>乘 mask 矩阵（正常 token 的值为 0，要丢弃的 token 值为 1w）使得正常 token 的值维持原状，被丢弃的 token 值很小。使得进过 softmax 之后，不想要被注意的值无限趋于 0</p>\n<p>进行 softmax 归一化得到注意力分数</p>\n<p>用 V 矩阵和注意力分数进行加权，再把不同头的分数合并起来</p>\n</li>\n<li>\n<p>残差连接 &amp; Normalisation<br>\n 相加操作与 ResNet 相似，相当于在求导时加了一个恒等项，减少梯度消失的问题</p>\n<p>Layer_Norm<br>\n 提升神经网络的泛化性<br>\n（数据的分布对模型可能会有很大的影响）<br>\n所以需要将隐藏层的输出都归一化成均值为 0 方差为 1 的分布<br>\n更好的利用模型在训练集中收获的知识<br>\n norm 放在激活函数之前，避免数据落入饱和区，减少梯度消失的问题<br>\n（实际操作时会初始化一个新的均值和方差，调整分布，增加多样性）</p>\n<pre><code> NLP的序列是变长的，Batch_Norm在对不同样本的同一个位置去做归一化时，无法获得真实分布的统计值。\n Layer_Norm会对同一个样本每一个位置的不同特征做归一化\n\n\n \n\n Normalisation可以放在不同的地方\n     Post-LayerNorm先做残差再归一化\n         保持主干网络的方差比较稳定，使模型泛化能力更强。\n         但把恒等的路径放在norm里，会导致模型更难收敛。\n     Pre-LayerNorm先归一化再做残差\n         更容易收敛，但只是增加了网络的宽度而不是深度，效果没有前者好。\n</code></pre>\n</li>\n<li>\n<p>Positionwise FFN (Feed Forward Network)<br>\n 提供了非线性变换，提升拟合能力 (1*1 卷积核的全连接层)。<br>\n激活层从 ReLU 变成了 GeLU，引入了正则的思想，越小的值越可能被丢弃掉，相当于 ReLU 和 dropout 的结合。<br>\ntanh 和 sigmoid 的双边区域会饱和，导致导数趋于 0，有梯度消失的问题。</p>\n</li>\n</ol>\n",
            "tags": [
                "神经网络",
                "自然语言处理"
            ]
        },
        {
            "id": "http://example.com/2024/02/24/projects/alzheimer/",
            "url": "http://example.com/2024/02/24/projects/alzheimer/",
            "title": "Alzheimer’s Disease Detection using Disfluencies Implemented Fine-Tuning BERT Model Ensemble",
            "date_published": "2024-02-23T16:00:00.000Z",
            "content_html": "<ol>\n<li>背景介绍<br>\n使用原始的、未注释的、未转录的语音进行目标认知状态预测，并解决认知随时间变化的预测。</li>\n</ol>\n<p>address 挑战：阿尔茨海默氏痴呆症识别仅通过自发语言</p>\n<ul>\n<li>从一个简短的演讲中检测阿尔茨海默氏痴呆症</li>\n<li>认知测试分数的推断，MMSE 分数。</li>\n<li>预测认知能力下降</li>\n</ul>\n<p>任务:<br>\n 从一个简短的演讲中检测阿尔茨海默氏痴呆症</p>\n<p>可能的一般方法:</p>\n<ul>\n<li>直接使用语音信号 (声学特征)</li>\n<li>语音自动转换为文本 (ASR)，并从脚本中提取语言特征</li>\n</ul>\n<p>更好的解决方案:<br>\n 结合声学和语言特征，利用预训练 BERT 模型。</p>\n",
            "tags": [
                "科研项目",
                "自然语言处理"
            ]
        },
        {
            "id": "http://example.com/2024/02/18/hello-world/",
            "url": "http://example.com/2024/02/18/hello-world/",
            "title": "Hello World",
            "date_published": "2024-02-18T10:04:35.837Z",
            "content_html": "<p>Welcome to <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvLw==\">Hexo</span>! This is your very first post. Check <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv\">documentation</span> for more info. If you get any problems when using Hexo, you can find the answer in <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=\">troubleshooting</span> or you can ask me on <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==\">GitHub</span>.</p>\n<h2 id=\"quick-start\"><a class=\"anchor\" href=\"#quick-start\">#</a> Quick Start</h2>\n<h3 id=\"create-a-new-post\"><a class=\"anchor\" href=\"#create-a-new-post\">#</a> Create a new post</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s\">Writing</span></p>\n<h3 id=\"run-server\"><a class=\"anchor\" href=\"#run-server\">#</a> Run server</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=\">Server</span></p>\n<h3 id=\"generate-static-files\"><a class=\"anchor\" href=\"#generate-static-files\">#</a> Generate static files</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s\">Generating</span></p>\n<h3 id=\"deploy-to-remote-sites\"><a class=\"anchor\" href=\"#deploy-to-remote-sites\">#</a> Deploy to remote sites</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvb25lLWNvbW1hbmQtZGVwbG95bWVudC5odG1s\">Deployment</span></p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2024/02/04/travel/japan/food/",
            "url": "http://example.com/2024/02/04/travel/japan/food/",
            "title": "日本行美食总结",
            "date_published": "2024-02-03T16:00:00.000Z",
            "content_html": "<h1 id=\"神户\"><a class=\"anchor\" href=\"#神户\">#</a> 神户</h1>\n<h2 id=\"くつろぎ家kutsurogiya\"><a class=\"anchor\" href=\"#くつろぎ家kutsurogiya\">#</a> くつろぎ家（Kutsurogiya）</h2>\n<p>网红的平价米其林（2016 年米其林推荐），招牌釜饭确实好吃 <strong>『くつろぎ釜飯』</strong>，内涵鲷鱼鲑鱼章鱼及蔬菜，味道很有层次。网红的蒸和牛 **『湯けむり蒸し』** 是牛肉与蔬菜在小蒸笼里现场蒸制，本身没有调味，即便有酱料蘸碟还是觉得乏善可陈。当地人基本都只点釜饭，点和牛的都是游客。有小碟点心小菜，杏仁豆腐什么的。冬季限定有牡蛎釜饭。</p>\n<p>有馬温泉駅 徒歩 5 分 日式榻榻米风格餐厅</p>\n<p>不支持预定，仅能 walk-in 排队，cash only，人均 200+RMB</p>\n<h2 id=\"神戸豚骨ラーメン-賀正軒gashoken\"><a class=\"anchor\" href=\"#神戸豚骨ラーメン-賀正軒gashoken\">#</a> 神戸豚骨ラーメン 賀正軒（Gashoken）</h2>\n<p>除了传统的豚骨拉面外 <strong>『白賀正』</strong>，还有罗勒调味的 <strong>『翠賀正』</strong>、黑蒜墨鱼汁调味的 <strong>『黑賀正』</strong> 和辣味的 <strong>『赤賀正』</strong>，面里加水饺，大海苔，汤底偏咸。</p>\n<p>三宫站附近 日式居酒屋风格餐厅</p>\n<p>有点餐机 可中文 多种支付方式</p>\n<h1 id=\"大阪\"><a class=\"anchor\" href=\"#大阪\">#</a> 大阪</h1>\n<h2 id=\"北極星-心齋橋本店\"><a class=\"anchor\" href=\"#北極星-心齋橋本店\">#</a> 北極星 心齋橋本店</h2>\n<p>百年历史老店，可选鸡肉 / 火腿 / 蘑菇 / 牛肉 / 蟹肉<strong>蛋包饭</strong>，辅以番茄酱汁（好像也有咖喱酱），可选 Topping 配菜炸物。是一份品质很不错的蛋包饭，但也仅此而已了。</p>\n<p>不支持预定，门口 iPad 上取号后排队，日式居榻榻米风格餐厅</p>\n<p>有中文菜单，支持信用卡支付</p>\n<h2 id=\"お好み鉄板酒場-どら十doraju\"><a class=\"anchor\" href=\"#お好み鉄板酒場-どら十doraju\">#</a> お好み鉄板酒場 どら十（Doraju）</h2>\n<p>小巷子里的热门<strong>大阪烧</strong>小作坊，仅有两名店员，样本观察顾客中国人居多，看不懂菜单的都点 MIX 大阪烧。也有蛋包饭、炒面、和牛、炸物烤物小吃等。入座必须要点一杯饮料。大阪烧做的确实不错，可选内料，表皮非常酥脆，内馅绵软柔密</p>\n<p>心斎橋駅 徒歩 3 分 日式居酒屋风格餐厅 座位少</p>\n<p>可在线预约 日文菜单 支持插入式信用卡</p>\n<h2 id=\"銀座-篝拉麵-lucua大阪店\"><a class=\"anchor\" href=\"#銀座-篝拉麵-lucua大阪店\">#</a> 銀座 篝拉麵 LUCUA 大阪店</h2>\n<p>16、17 年的米其林推荐的网红<strong>拉面</strong>，招牌鸡白汤拉面和花蛤牡蛎海鲜拉面。海鲜汤底有点鲜过头了，花蛤可能是熬汤后的产品，所以本身没有什么味道，牡蛎干货味道重，不是特别适合作为配菜。面条没有煮的很入味，面粉味还是非常明显的。Topping 是低温慢煮的鸡肉和猪肉，个人认为鸡肉没有处理的特别好，猪肉比较好吃。小碟是柚子皮和炸洋葱。总体而言除了汤底鲜甜，其他并不是很配得上他的价格和排队时间。</p>\n<p>大阪梅田 LUCUA 地下一层，排队久</p>\n<p>有中英文菜单，可使用信用卡和 suica</p>\n<h1 id=\"京都\"><a class=\"anchor\" href=\"#京都\">#</a> 京都</h1>\n<h2 id=\"やきとり大吉-堀川高辻店daikichi-horikawa-takatsuji\"><a class=\"anchor\" href=\"#やきとり大吉-堀川高辻店daikichi-horikawa-takatsuji\">#</a> やきとり大吉 堀川高辻店（Daikichi Horikawa Takatsuji）</h2>\n<p>非常物美价廉的日式烧鸟店，大部分鸡肉部位烧串都有，特殊部分没有（提灯什么的），单串价格都在十元以内。夫妻经营，人多时上菜稍慢。但是现场烤制味道好，厨师会英文可以聊天。还有烤饭团鸡肉汤和主食小吃，味道比较稀松平常。入座必须要点一杯饮料，送了一碗卷心菜沙拉。</p>\n<p>大宮駅附近，日式居酒屋风格餐厅，店内位置少</p>\n<p>有中英文菜单，可以支付宝</p>\n<h2 id=\"smart-咖啡店\"><a class=\"anchor\" href=\"#smart-咖啡店\">#</a> Smart 咖啡店</h2>\n<p>少有的早餐店（虽然便利店和一般咖啡店也可以吃早饭）。法式吐司外层浸透了蛋液，烘焙出的焦化外壳非常酥脆，内部吐司绵软，有蜂蜜甜浆搭配，不会太甜（甜品的最高评价是不甜）。舒芙蕾松饼和各种三明治也做的不错，手工焦糖布丁口感密实。有各种饮品可点。二楼有提供午餐，经典的一些日式西餐。</p>\n<p>京都市役所前駅 徒歩 1 分 西式复古风格餐厅 环境氛围好</p>\n<p>英文菜单 多种支付方式 通常都会排队</p>\n<h2 id=\"麺屋-猪一\"><a class=\"anchor\" href=\"#麺屋-猪一\">#</a> 麺屋 猪一</h2>\n<p>连续八年获得米其林推荐的拉面馆，汤头确实是醇厚鲜香的没话说，据说是不使用猪肉鸡肉等动物脂肪，仅用鲣鱼片提取的海鲜高汤，可以选择白酱油还是黑酱油汤底，黑酱油是二次熟成的，味道更厚一点。可以搭配柚子皮小碟解腻，面条几乎没有缺点，劲道入味。桌上有调味粉可选（黑七味粉 / 山椒粉 / 昆布等），Topping 可以选炙烤和牛或者温泉蛋等。有丼饭和烧麦小吃可选。</p>\n<p>京都河原町駅 徒歩 6 分 日式风格餐厅</p>\n<p>京都有两家店 只接受现场排队 店里不能随便拍照 只能拍食物 甚至有周边衣服和料理包卖 排队久</p>\n<h2 id=\"maccha-house-抹茶館-京都清水産寧坂\"><a class=\"anchor\" href=\"#maccha-house-抹茶館-京都清水産寧坂\">#</a> MACCHA HOUSE 抹茶館 京都清水産寧坂</h2>\n<p>仅尝了一下宇治抹茶提拉米苏，最底下是抹茶戚风蛋糕，中间层起司内馅，上面撒抹茶粉。蛋糕被浸泡的有点潮比较影响口感，但整体内馅和抹茶的味道都是极好的，很香，不甜！最高评价。但其实在二三年坂商业街的抹茶甜点比比皆是，口味应该大差不差。</p>\n<p>巴士『清水道』站下车步行 6 分钟 日式庭院风格甜品店</p>\n<p>在日本拥有 7 家门店，有英文菜单，多种支付方式</p>\n<h2 id=\"sushitetsu\"><a class=\"anchor\" href=\"#sushitetsu\">#</a> Sushitetsu</h2>\n<p>京阪三条駅 徒歩 5 分 日式风格餐厅</p>\n<p>有中英文菜单 支持信用卡 现场排队需要先门口填名字再排队</p>\n",
            "tags": [
                "旅行日志",
                "日本跨年行",
                "旅行",
                "唯有美食与爱不可辜负"
            ]
        },
        {
            "id": "http://example.com/2024/02/04/travel/japan/route/",
            "url": "http://example.com/2024/02/04/travel/japan/route/",
            "title": "15天9城特种兵行程总结",
            "date_published": "2024-02-03T16:00:00.000Z",
            "content_html": "<h1 id=\"關西\"><a class=\"anchor\" href=\"#關西\">#</a> 關西</h1>\n<p>⌀ 1.21 神戶 DAY1</p>\n<p>厦门高崎机场 --&gt; 大阪关西机场</p>\n<p>⌀ 1.22 大阪 DAY2 市內景點走走</p>\n<p>⌀ 1.23 大阪 DAY3 環球影城？？or 機動</p>\n<p>⌀ 1.24 京都 DAY4 市內走走</p>\n<p>⌀ 1.25 京都 DAY5 市周圍走走？ 可以嵐山 或者宇治</p>\n<p>⌀ 1.26 奈良 DAY6</p>\n<p>⌀ 1.27 名古屋 DAY7 真不一定去吧 可以換箱根或者鐮倉？或者加到東京去</p>\n<h1 id=\"關東\"><a class=\"anchor\" href=\"#關東\">#</a> 關東</h1>\n<p>⌀ 1.28 富士山 DAY1</p>\n<p>⌀ 1.29 東京 DAY2 淺草寺 晴空塔 秋葉原 新宿歌舞町 天空樹</p>\n<p>⌀ 1.30 東京 DAY3 東京塔 明治神宮 代代木公園 澀谷 sky 穿插</p>\n<p>⌀ 1.31 東京 DAY4 機動 下午或晚上需要到達坐船點或者飛機點</p>\n<h1 id=\"北海道\"><a class=\"anchor\" href=\"#北海道\">#</a> 北海道</h1>\n<p>⌀ 2.1 札幌 DAY1 市中心走景點：圆山动物园→北海道神宫→白色恋人工厂→JR 塔展望室 T38 (夜景)→  狸小路 → 二条市场→札幌电视塔（大通公园 / 札幌钟楼）→ 中岛公园（或头大佛）→ 藻岩山展望台 (夜景)</p>\n<p>⌀ 2.2 札幌 DAY2 找個交通好一點的地方滑雪 酒店可不變 （19 號來的人該走了）</p>\n<p>⌀ 2.3 小樽 DAY3 市中心走 可以住小樽或者札幌 情懷散步</p>\n<p>⌀ 登別 DAY4</p>\n<p>⌀ 函館 DAY5</p>\n",
            "tags": [
                "旅行日志",
                "日本跨年行",
                "旅行"
            ]
        },
        {
            "id": "http://example.com/2021/06/20/travel/xinjiang/xinjiang/",
            "url": "http://example.com/2021/06/20/travel/xinjiang/xinjiang/",
            "title": "跨越山海|新疆自驾毕业旅行",
            "date_published": "2021-06-19T16:00:00.000Z",
            "content_html": "",
            "tags": [
                "旅行日志",
                "旅行"
            ]
        }
    ]
}